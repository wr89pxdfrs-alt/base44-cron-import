# scraper.py
import json
import requests
from bs4 import BeautifulSoup
from datetime import datetime

OUTPUT_FILE = "annonces.json"

def scrape_demo():
    # SITE DE TEST QUI RETOURNE DES DONNÉES EN HTML (ACCESSIBLE)
    url = "https://books.toscrape.com"   # SITE D'ENTRAÎNEMENT SCRAPING
    r = requests.get(url, timeout=20)
    
    soup = BeautifulSoup(r.text, "html.parser")

    annonces = []

    for item in soup.select(".product_pod"):
        try:
            title = item.select_one("h3 a")["title"]
            price = item.select_one(".price_color").get_text(strip=True)

            annonces.append({
                "titre": title,
                "prix": price,
                "ville": "TestCity",
                "surface": None,
                "url_originale": url,
                "photos": [],
                "source": "demo_scraper",
                "date_import": datetime.utcnow().isoformat()
            })
        except:
            pass

    return annonces


def main():
    all_annonces = scrape_demo()

    with open(OUTPUT_FILE, "w", encoding="utf8") as f:
        json.dump(all_annonces, f, ensure_ascii=False, indent=2)

    print(f"{len(all_annonces)} annonces exportées")


if __name__ == "__main__":
    main()
